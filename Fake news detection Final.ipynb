{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import scipy.optimize\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import string\n",
    "from nltk.stem.porter import *\n",
    "from sklearn import linear_model\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import requests\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from random import randint\n",
    "\n",
    "import json\n",
    "from os import makedirs\n",
    "from os.path import join, exists\n",
    "from datetime import date, timedelta\n",
    "\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn import tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>statement</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>half-true</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>false</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>half-true</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>true</td>\n",
       "      <td>The Chicago Bears have had more starting quart...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         label                                          statement  score\n",
       "1    half-true  When did the decline of coal start? It started...      0\n",
       "2  mostly-true  Hillary Clinton agrees with John McCain \"by vo...      1\n",
       "3        false  Health care reform legislation is likely to ma...     -1\n",
       "4    half-true  The economic turnaround started at the end of ...      0\n",
       "5         true  The Chicago Bears have had more starting quart...      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_full = pd.DataFrame.from_csv('processed_data.csv',sep=\",\")\n",
    "data, data_test = train_test_split(data_full, test_size=0.2)\n",
    "data_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unigrams and Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwordlist = stopwords.words(\"english\")\n",
    "punctuation = set(string.punctuation)\n",
    "\n",
    "# split training data to 3 classes\n",
    "d_true = data[data.score==1]\n",
    "d_false = data[data.score==-1]\n",
    "d_amb = data[data.score==0]\n",
    "\n",
    "unigrams = dict()\n",
    "unigrams['true'] = defaultdict(int)\n",
    "unigrams['false'] = defaultdict(int)\n",
    "unigrams['amb'] = defaultdict(int)\n",
    "unigrams['all'] = defaultdict(int)\n",
    "bigrams = dict()\n",
    "bigrams['true'] = defaultdict(int)\n",
    "bigrams['false'] = defaultdict(int)\n",
    "bigrams['amb'] = defaultdict(int)\n",
    "bigrams['all'] = defaultdict(int)\n",
    "\n",
    "# finding frequent unigrams and bigrams for the three classes\n",
    "for d1,d2 in zip(data.score, data.statement):\n",
    "    r = ''.join([c for c in d2.lower() if not c in punctuation])\n",
    "    w1 = None       \n",
    "    for w in r.split():\n",
    "        if w not in stopwordlist :\n",
    "            if d1 == 1 :\n",
    "                unigrams['true'][w] += 1\n",
    "                if w1 :\n",
    "                    bigrams['true'][w1+' '+w] += 1\n",
    "            if d1 == -1 :\n",
    "                unigrams['false'][w] += 1\n",
    "                if w1 :\n",
    "                    bigrams['false'][w1+' '+w] += 1\n",
    "            if d1 == 0 :\n",
    "                unigrams['amb'][w] += 1\n",
    "                if w1 :\n",
    "                    bigrams['amb'][w1+' '+w] += 1    \n",
    "            w1 = w\n",
    "            \n",
    "def freq_words(dict1, dict2, n=1000) : ## n = Number of unigrams and bigrams (hyperparameter)\n",
    "    words = [(dict1[w], w) for w in dict1 if w.isdigit() == False]\n",
    "    words.sort(reverse = True)\n",
    "    words = [x[1] for x in words[:n]]\n",
    "    bi = [(dict2[w], w) for w in dict2]\n",
    "    bi.sort(reverse = True)\n",
    "    bi = [x[1] for x in bi[:n]]\n",
    "    comb = words + bi\n",
    "    comb_ID = dict(zip(comb, range(len( comb))))\n",
    "    return comb,comb_ID, words\n",
    "\n",
    "# combination of bigrams and unigrams\n",
    "comb_true, comb_true_id, words_true = freq_words( unigrams['true'], bigrams['true'] )\n",
    "comb_false, comb_false_id, words_false = freq_words( unigrams['false'], bigrams['false'] )\n",
    "comb_amb, comb_amb_id, words_amb = freq_words( unigrams['amb'], bigrams['amb'] )\n",
    "\n",
    "# combination of bigrams and unigrams from all three classes\n",
    "comb_full = list( set( comb_true + comb_false + comb_amb ) )\n",
    "comb_full_id = dict(zip(comb_full, range(len( comb_full ))))\n",
    "\n",
    "# combination of frequent unigrams from the three classes\n",
    "words_full = list( set( words_true + words_false + words_amb ))\n",
    "words_full_id = dict(zip(words_full, range(len( words_full ))))            \n",
    "\n",
    "def feature(datum, comb, comb_id):\n",
    "    feat = [0]*len(comb)\n",
    "    temp = []\n",
    "    r = ''.join([c for c in datum.lower() if not c in punctuation])\n",
    "    w1 = None\n",
    "    for w in r.split():\n",
    "        temp.append(w)\n",
    "        if w in comb:\n",
    "            feat[comb_id[w]] += 1\n",
    "        if w1 :\n",
    "            bi = str( w1+' '+w )\n",
    "            if bi in comb :\n",
    "                feat[comb_id[bi]] += 1\n",
    "        w1 = w\n",
    "    feat.append(1)\n",
    "    return feat\n",
    "\n",
    "# features, using entire datasets (to get + and- samples)\n",
    "# using unigrams and bigrams of true, false and amb cases respectively\n",
    "X_ngram_true = np.array( [feature(d, comb_true, comb_true_id ) for d in data.statement ]  )\n",
    "X_ngram_false = np.array( [feature(d, comb_false, comb_false_id ) for d in data.statement ] )\n",
    "X_ngram_amb = np.array( [feature(d, comb_amb, comb_amb_id ) for d in data.statement ] )\n",
    "X_ngram_full = np.array( [feature(d, comb_full, comb_full_id ) for d in data.statement ] )\n",
    "\n",
    "X_ngram_true_test = np.array( [feature(d, comb_true, comb_true_id ) for d in data_test.statement ] )\n",
    "X_ngram_false_test = np.array( [feature(d, comb_false, comb_false_id ) for d in data_test.statement ] )\n",
    "X_ngram_amb_test = np.array( [feature(d, comb_amb, comb_amb_id ) for d in data_test.statement ] )\n",
    "\n",
    "y_ngram_true = np.array([d==1 for d in data['score']]) \n",
    "y_ngram_false = np.array([d==-1 for d in data['score']])\n",
    "y_ngram_amb = np.array([d==0 for d in data['score']])\n",
    "y_ngram_full = np.array( [d for d in data['score']] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accu2(y_test,pred1) :\n",
    "    accu = 100*np.sum(pred1 == y_test)/len(pred1)\n",
    "    f_f = 100*np.sum( (pred1 == -1) & (y_test == -1))/np.sum( y_test == -1) # pred fake, label fake\n",
    "    f_t = 100*np.sum( (pred1 == 1) & (y_test == -1))/np.sum( y_test == -1)\n",
    "    t_t = 100*np.sum( (pred1 == 1) & (y_test == 1))/np.sum( y_test == 1)\n",
    "    t_f = 100*np.sum( (pred1 == -1) & (y_test == 1))/np.sum( y_test == 1)\n",
    "    ber = 1 - 0.5*( (t_t/(t_t+t_f)) + (f_f/(f_f+f_t)) )\n",
    "    print('Accuracy for testing = ', accu,'%')\n",
    "    print('BER = ', ber)\n",
    "    return accu, ber"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression using 500 unigram/bigrams alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_ngram_true' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-2d972cac1aed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mclf_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mclf_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_reg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_ngram_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ngram_true\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;31m# print('accuracy on training set for true class = ', accu )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mclf_false\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_false\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_reg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_ngram_false\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ngram_false\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_ngram_true' is not defined"
     ]
    }
   ],
   "source": [
    "def log_reg(X_true, y_true, lam = 1.0) :\n",
    "    clf_true = LogisticRegression()\n",
    "    clf_true.fit(X_true, y_true)\n",
    "    theta_true = clf_true.coef_\n",
    "    pred_true = clf_true.predict(X_true)\n",
    "    pred_true = np.array([x >0.5 for x in pred_true])\n",
    "    accu = np.sum( (y_true==pred_true) )/len(data) \n",
    "    return clf_true, pred_true, accu \n",
    "\n",
    "clf_true, pred_true, accu = log_reg(X_ngram_true, y_ngram_true ) \n",
    "# print('accuracy on training set for true class = ', accu )\n",
    "clf_false, pred_false, accu = log_reg(X_ngram_false, y_ngram_false ) \n",
    "# print('accuracy on training set for false class = ', accu )\n",
    "clf_amb, pred_amb, accu = log_reg(X_ngram_amb, y_ngram_amb ) \n",
    "# print('accuracy on training set for amb class = ', accu )\n",
    "\n",
    "# X_ngram_true_test = [feature(d, comb_true, comb_true_id ) for d in data_test.statement ]\n",
    "# X_ngram_false_test = [feature(d, comb_false, comb_false_id ) for d in data_test.statement ]\n",
    "# X_ngram_amb_test = [feature(d, comb_amb, comb_amb_id ) for d in data_test.statement ]\n",
    "\n",
    "y_ngram_true_test = [d==1 for d in data_test['score']]\n",
    "y_ngram_false_test = [d==-1 for d in data_test['score']]\n",
    "y_ngram_amb_test = [d==0 for d in data_test['score']]\n",
    "\n",
    "pred_true_test = list( clf_true.predict(X_ngram_true_test) )\n",
    "pred_false_test = list( clf_false.predict(X_ngram_false_test) )\n",
    "pred_amb_test = list( clf_amb.predict(X_ngram_amb_test) )\n",
    "\n",
    "pred_tests = [pred_false_test,pred_amb_test, pred_true_test]\n",
    "y_test = np.array(data_test['score'])\n",
    "pred_test = np.argmax(pred_tests,axis=0)-1\n",
    "def accu(y_test,pred1) :\n",
    "    accu = 100*np.sum(pred1 == y_test)/len(pred1)\n",
    "    f_f = 100*np.sum( (pred1 == -1) & (y_test == -1))/np.sum( y_test == -1) # pred fake, label fake\n",
    "    f_t = 100*np.sum( (pred1 == 1) & (y_test == -1))/np.sum( y_test == -1)\n",
    "    t_t = 100*np.sum( (pred1 == 1) & (y_test == 1))/np.sum( y_test == 1)\n",
    "    t_f = 100*np.sum( (pred1 == -1) & (y_test == 1))/np.sum( y_test == 1)\n",
    "    ber = 1 - 0.5*( (t_t/(t_t+t_f)) + (f_f/(f_f+f_t)) )\n",
    "    print('Accuracy for testing = ', accu,'%')\n",
    "    print('Fake news predicted as Fake = ', f_f,\"%\")\n",
    "    print('Fake news mispredicted as True = ', f_t,\"%\")\n",
    "    print('True news predicted as True = ', t_t,\"%\")\n",
    "    print('True news mispredicted as Fake = ', t_f,\"%\")\n",
    "    print('BER = ', ber)\n",
    "\n",
    "accu(y_test,pred_test) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for testing =  81.2208760485 %\n",
      "Fake news predicted as Fake =  42.5688661115 %\n",
      "Fake news mispredicted as True =  53.7796284433 %\n",
      "True news predicted as True =  97.4550761653 %\n",
      "True news mispredicted as Fake =  1.25877953115 %\n",
      "BER =  0.285464996687\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred_true_test = list( clf_true.predict(X_ngram_true_test) )\n",
    "pred_false_test = list( clf_false.predict(X_ngram_false_test) )\n",
    "pred_amb_test = list( clf_amb.predict(X_ngram_amb_test) )\n",
    "\n",
    "pred_tests = [pred_false_test,pred_amb_test, pred_true_test]\n",
    "y_test = np.array(data_test['score'])\n",
    "pred_test = np.argmax(pred_tests,axis=0)-1\n",
    "accu(y_test,pred_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_components = 30\n",
    "n_words = 30\n",
    "n_features = 1000\n",
    "d_true = data[data.score==1]\n",
    "d_false = data[data.score==-1]\n",
    "d_amb = data[data.score==0]\n",
    "\n",
    "def TFIDF_vec(data, n_features):\n",
    "# Use tf-idf features.\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2,max_features=n_features,stop_words='english')\n",
    "    tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2,max_features=n_features,stop_words='english') \n",
    "    tf = tf_vectorizer.fit_transform(data)\n",
    "    tfidf = tfidf_vectorizer.fit_transform(data)\n",
    "    tfidf = tfidf.toarray()\n",
    "    tf = tf.toarray()\n",
    "    idf = tfidf_vectorizer.idf_\n",
    "    words = tfidf_vectorizer.get_feature_names()\n",
    "    word_id = dict(zip(words, range(len( words ))))\n",
    "    return tf, tfidf, words, idf, word_id\n",
    "\n",
    "def TF(datum, words,wordID, idf) :\n",
    "    tf = [0]*len(words)\n",
    "    for i in words :\n",
    "        s = datum.lower().split()\n",
    "        tf[wordID[i]] = s.count(i)\n",
    "    return tf\n",
    "\n",
    "def TFIDF(datum, words,wordID, idf) :\n",
    "    tf = [0]*len(words)\n",
    "    for i in words :\n",
    "        s = datum.lower().split()\n",
    "        tf[wordID[i]] = s.count(i) * idf[wordID[i]]\n",
    "    return tf\n",
    "\n",
    "tf_true, tfidf_true,words_true, idf_true, words_true_id = TFIDF_vec(d_true['statement'], n_features)\n",
    "tf_amb, tfidf_amb,words_amb, idf_amb, words_amb_id = TFIDF_vec(d_amb['statement'], n_features)\n",
    "tf_false, tfidf_false,words_false, idf_false, words_false_id = TFIDF_vec(d_false['statement'], n_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def features_TFIDF(datum) :\n",
    "    tf1 =  np.array( TFIDF(datum,words_true,words_true_id,idf_true)  ).reshape(1,len(words_true))\n",
    "    tf2 =  np.array( TFIDF(datum,words_false,words_false_id,idf_false)  ).reshape(1,len(words_true))\n",
    "    tf3 =  np.array( TFIDF(datum,words_amb,words_amb_id,idf_amb)  ).reshape(1,len(words_true))\n",
    "    return np.column_stack((tf1,tf2,tf3))\n",
    "\n",
    "X_TFIDF = [features_TFIDF(datum ) for datum in data.statement]\n",
    "X_TFIDF = np.array( X_TFIDF ).reshape(len(data),len(words_true)*3)\n",
    "X_TFIDF_test = [features_TFIDF(datum ) for datum in data_test.statement]\n",
    "X_TFIDF_test = np.array( X_TFIDF_test ).reshape(len(data_test),len(words_true)*3)  \n",
    "\n",
    "X_ngram = np.column_stack((X_ngram_true,X_ngram_false,X_ngram_amb))\n",
    "X_ngram_test  = np.column_stack((X_ngram_true_test ,X_ngram_false_test ,X_ngram_amb_test))\n",
    "X_ngram_val = X_ngram_test[:5000,:]\n",
    "X_ngram_test = X_ngram_test[5000:,:]\n",
    "X_TFIDF_val = X_TFIDF_test[:5000,:]\n",
    "X_TFIDF_test = X_TFIDF_test[5000:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMF and LDA Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nmf_true = NMF(n_components=n_components, random_state=1, alpha=.1, l1_ratio=.5)\n",
    "nmf_false = NMF(n_components=n_components, random_state=1, alpha=.1, l1_ratio=.5)\n",
    "nmf_amb = NMF(n_components=n_components, random_state=1, alpha=.1, l1_ratio=.5)\n",
    "\n",
    "nmf_amb.fit(tf_amb)\n",
    "nmf_false.fit(tf_false)\n",
    "nmf_true.fit(tf_true)\n",
    "\n",
    "def NMF_features(datum ): \n",
    "    tf = TFIDF(datum,words_true,words_true_id,idf_true)\n",
    "    x1 = nmf_true.transform( np.array(tf).reshape(1,-1) )\n",
    "    tf = TFIDF(datum,words_false,words_false_id,idf_false)\n",
    "    x2 = nmf_false.transform( np.array(tf).reshape(1,-1) )\n",
    "    tf = TFIDF(datum,words_amb,words_amb_id,idf_amb)\n",
    "    x3 = nmf_amb.transform( np.array(tf).reshape(1,-1) )\n",
    "    return np.column_stack((x1,x2,x3))\n",
    "\n",
    "X_NMF = [NMF_features(datum ) for datum in data.statement]\n",
    "X_NMF = np.array( X_NMF ).reshape(len(data),n_components*3)\n",
    "X_NMF_test = [NMF_features(datum ) for datum in data_test.statement]\n",
    "X_NMF_test = np.array( X_NMF_test ).reshape(len(data_test),n_components*3)\n",
    "\n",
    "lda_true = LatentDirichletAllocation(n_topics=n_components, max_iter=5, \n",
    "                                    learning_method='online', learning_offset=50.,random_state=0)\n",
    "lda_false = LatentDirichletAllocation(n_topics=n_components, max_iter=5, \n",
    "                                    learning_method='online', learning_offset=50.,random_state=0)\n",
    "lda_amb = LatentDirichletAllocation(n_topics=n_components, max_iter=5, \n",
    "                                    learning_method='online', learning_offset=50.,random_state=0)\n",
    "lda_amb.fit(tf_amb)\n",
    "lda_false.fit(tf_false)\n",
    "lda_true.fit(tf_true)\n",
    "\n",
    "def LDA_features(datum ): \n",
    "    tf = TF(datum,words_true,words_true_id,idf_true)\n",
    "    x1 = lda_true.transform( np.array(tf).reshape(1,-1) )\n",
    "    tf = TF(datum,words_false,words_false_id,idf_false)\n",
    "    x2 = lda_false.transform( np.array(tf).reshape(1,-1) )\n",
    "    tf = TF(datum,words_amb,words_amb_id,idf_amb)\n",
    "    x3 = lda_amb.transform( np.array(tf).reshape(1,-1) )\n",
    "    return np.column_stack((x1,x2,x3))\n",
    "\n",
    "X_LDA = [LDA_features(datum ) for datum in data.statement]\n",
    "X_LDA = np.array( X_LDA ).reshape(len(data),n_components*3)\n",
    "X_LDA_test = [LDA_features(datum ) for datum in data_test.statement]\n",
    "X_LDA_test = np.array( X_LDA_test ).reshape(len(data_test),n_components*3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60085, 6183)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ngram = np.column_stack((X_ngram_true,X_ngram_false,X_ngram_amb ))\n",
    "X_ngram_test  = np.column_stack((X_ngram_true_test ,X_ngram_false_test ,X_ngram_amb_test ))\n",
    "\n",
    "X = np.column_stack((X_LDA,X_NMF,X_ngram))\n",
    "X_test = np.column_stack((X_LDA_test,X_NMF_test,X_ngram_test))\n",
    "X.shape\n",
    "\n",
    "y = np.array( [d for d in data['score']  ] )\n",
    "y_test = np.array( [d for d in data_test['score']] )\n",
    "\n",
    "X_ngram = np.column_stack((X_ngram_true,X_ngram_false,X_ngram_amb ))\n",
    "X_ngram_test  = np.column_stack((X_ngram_true_test ,X_ngram_false_test ,X_ngram_amb_test ))\n",
    "X = np.column_stack((X_LDA,X_NMF,X_ngram))\n",
    "X_test = np.column_stack((X_LDA_test,X_NMF_test,X_ngram_test))\n",
    "\n",
    "# X = np.column_stack((X_TFX_ngram))\n",
    "# X_test = np.column_stack((X_TFIDF_test,X_ngram_test))\n",
    "\n",
    "clf = LinearSVC(random_state=0)\n",
    "clf.fit(X, y)\n",
    "pred1 = clf.predict(X_test)\n",
    "accu(y_test,pred1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logisitc regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for testing =  82.1927839169 %\n",
      "Fake news predicted as Fake =  61.1467008328 %\n",
      "Fake news mispredicted as True =  38.8532991672 %\n",
      "True news predicted as True =  95.2111648271 %\n",
      "True news mispredicted as Fake =  4.78883517285 %\n",
      "BER =  0.181219810364\n"
     ]
    }
   ],
   "source": [
    "y = y1\n",
    "y_test = y_test1\n",
    "\n",
    "X = np.column_stack((X_LDA,X_NMF,X_ngram,X_TFIDF))\n",
    "X_test = np.column_stack((X_LDA_test,X_NMF_test,X_ngram_test,X_TFIDF_test))\n",
    "\n",
    "clf = linear_model.Ridge(1.0, fit_intercept=False)\n",
    "clf.fit(X, y)\n",
    "pred1= clf.predict(X_test)\n",
    "for i in range(len(pred1)) :\n",
    "    if pred1[i]<-0.8:\n",
    "        pred1[i] = -1\n",
    "    else:\n",
    "        pred1[i] = 1 \n",
    "accu(y_test,pred1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for testing =  79.0906670217 %\n",
      "Fake news predicted as Fake =  58.7271581601 %\n",
      "Fake news mispredicted as True =  33.1442974165 %\n",
      "True news predicted as True =  89.3900422561 %\n",
      "True news mispredicted as Fake =  7.56016902444 %\n",
      "BER =  0.219374044206\n"
     ]
    }
   ],
   "source": [
    "y = np.array( [d for d in data['score']  ] )\n",
    "y_test = np.array( [d for d in data_test['score']] )\n",
    "\n",
    "X = np.column_stack((X_LDA,X_ngram))\n",
    "X_test = np.column_stack((X_LDA_test,X_ngram_test))\n",
    "\n",
    "clf_tree = tree.DecisionTreeClassifier()\n",
    "clf_tree.fit(X, y)\n",
    "predtree = clf_tree.predict(X_test)\n",
    "accu(y_test,predtree) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP using ngrams, NMF and LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "X = np.column_stack((X_LDA,X_NMF,X_ngram,X_TFIDF))\n",
    "X_test = np.column_stack((X_LDA_test,X_NMF_test,X_ngram_test,X_TFIDF_test))\n",
    "\n",
    "y = np.array( [d for d in data['score']  ] )\n",
    "y_test = np.array( [d for d in data_test['score']] )\n",
    "\n",
    "clf = MLPClassifier( hidden_layer_sizes=(50,10,3), random_state=1)\n",
    "clf.fit(X, y)\n",
    "pred1 = clf.predict(X_test)\n",
    "accu(y_test,pred1) \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
